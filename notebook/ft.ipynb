{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ce08dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np,pandas as pd,seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57915968",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px,warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57d4011b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('EasyVisa.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "542bec5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_with_na=[i for i in df.columns if df[i].isnull().sum()>=1]\n",
    "for i in features_with_na:\n",
    "    print(i,np.round(df[i].isnull().mean()*100,5),' %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5af72440",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_with_na"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fe2d7e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('case_id',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "35e3283a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we have 3 numerical : ['no_of_employees', 'yr_of_estab', 'prevailing_wage']\n",
      "we have 8 categorical : ['continent', 'education_of_employee', 'has_job_experience', 'requires_job_training', 'region_of_employment', 'unit_of_wage', 'full_time_position', 'case_status']\n"
     ]
    }
   ],
   "source": [
    "num_features=[i for i in df.columns if df[i].dtype!='O']\n",
    "cat_features=[j for j in df.columns if df[j].dtype=='O']\n",
    "print('we have {} numerical : {}'.format(len(num_features),num_features))\n",
    "print('we have {} categorical : {}'.format(len(cat_features),cat_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "912d1596",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df.drop('case_status',axis=1)\n",
    "y=df['case_status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "45ccd986",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=np.where(y=='Denied',1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a6d7bdc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3e8de842",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "full_time_position\n",
       "Y    22773\n",
       "N     2707\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['full_time_position'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c8f45724",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "  \n",
    "# creating the date object of today's date\n",
    "todays_date = date.today()\n",
    "current_year= todays_date.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f5b8f6fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['company_age'] = current_year-df['yr_of_estab']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6c749ab3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['continent', 'education_of_employee', 'has_job_experience',\n",
       "       'requires_job_training', 'no_of_employees', 'yr_of_estab',\n",
       "       'region_of_employment', 'prevailing_wage', 'unit_of_wage',\n",
       "       'full_time_position', 'case_status', 'company_age'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f34bc500",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['no_of_employees', 'yr_of_estab', 'prevailing_wage']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_features = list(x.select_dtypes(exclude=\"object\").columns)\n",
    "num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e42817c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "or_columns = ['has_job_experience','requires_job_training','full_time_position','education_of_employee']\n",
    "oh_columns = ['continent','unit_of_wage','region_of_employment']\n",
    "transform_columns= ['no_of_employees','company_age']\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler,OrdinalEncoder, PowerTransformer\n",
    "from sklearn.compose import ColumnTransformer \n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "numeric_transformer = StandardScaler()\n",
    "oh_transformer = OneHotEncoder()\n",
    "ordinal_encoder = OrdinalEncoder()\n",
    "\n",
    "transform_pipe = Pipeline(steps=[\n",
    "    ('transformer', PowerTransformer(method='yeo-johnson'))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    [\n",
    "        (\"OneHotEncoder\", oh_transformer, oh_columns),\n",
    "        (\"Ordinal_Encoder\", ordinal_encoder, or_columns),\n",
    "        (\"Transformer\", transform_pipe, transform_columns),\n",
    "        (\"StandardScaler\", numeric_transformer, num_features)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a2c8b6a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>continent</th>\n",
       "      <th>education_of_employee</th>\n",
       "      <th>has_job_experience</th>\n",
       "      <th>requires_job_training</th>\n",
       "      <th>no_of_employees</th>\n",
       "      <th>yr_of_estab</th>\n",
       "      <th>region_of_employment</th>\n",
       "      <th>prevailing_wage</th>\n",
       "      <th>unit_of_wage</th>\n",
       "      <th>full_time_position</th>\n",
       "      <th>company_age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Asia</td>\n",
       "      <td>High School</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>14513</td>\n",
       "      <td>2007</td>\n",
       "      <td>West</td>\n",
       "      <td>592.2029</td>\n",
       "      <td>Hour</td>\n",
       "      <td>Y</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Asia</td>\n",
       "      <td>Master's</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>2412</td>\n",
       "      <td>2002</td>\n",
       "      <td>Northeast</td>\n",
       "      <td>83425.6500</td>\n",
       "      <td>Year</td>\n",
       "      <td>Y</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Asia</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>44444</td>\n",
       "      <td>2008</td>\n",
       "      <td>West</td>\n",
       "      <td>122996.8600</td>\n",
       "      <td>Year</td>\n",
       "      <td>Y</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Asia</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>98</td>\n",
       "      <td>1897</td>\n",
       "      <td>West</td>\n",
       "      <td>83434.0300</td>\n",
       "      <td>Year</td>\n",
       "      <td>Y</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Africa</td>\n",
       "      <td>Master's</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>1082</td>\n",
       "      <td>2005</td>\n",
       "      <td>South</td>\n",
       "      <td>149907.3900</td>\n",
       "      <td>Year</td>\n",
       "      <td>Y</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25475</th>\n",
       "      <td>Asia</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>2601</td>\n",
       "      <td>2008</td>\n",
       "      <td>South</td>\n",
       "      <td>77092.5700</td>\n",
       "      <td>Year</td>\n",
       "      <td>Y</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25476</th>\n",
       "      <td>Asia</td>\n",
       "      <td>High School</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>3274</td>\n",
       "      <td>2006</td>\n",
       "      <td>Northeast</td>\n",
       "      <td>279174.7900</td>\n",
       "      <td>Year</td>\n",
       "      <td>Y</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25477</th>\n",
       "      <td>Asia</td>\n",
       "      <td>Master's</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>1121</td>\n",
       "      <td>1910</td>\n",
       "      <td>South</td>\n",
       "      <td>146298.8500</td>\n",
       "      <td>Year</td>\n",
       "      <td>N</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25478</th>\n",
       "      <td>Asia</td>\n",
       "      <td>Master's</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>1918</td>\n",
       "      <td>1887</td>\n",
       "      <td>West</td>\n",
       "      <td>86154.7700</td>\n",
       "      <td>Year</td>\n",
       "      <td>Y</td>\n",
       "      <td>138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25479</th>\n",
       "      <td>Asia</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>3195</td>\n",
       "      <td>1960</td>\n",
       "      <td>Midwest</td>\n",
       "      <td>70876.9100</td>\n",
       "      <td>Year</td>\n",
       "      <td>Y</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25480 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      continent education_of_employee has_job_experience  \\\n",
       "0          Asia           High School                  N   \n",
       "1          Asia              Master's                  Y   \n",
       "2          Asia            Bachelor's                  N   \n",
       "3          Asia            Bachelor's                  N   \n",
       "4        Africa              Master's                  Y   \n",
       "...         ...                   ...                ...   \n",
       "25475      Asia            Bachelor's                  Y   \n",
       "25476      Asia           High School                  Y   \n",
       "25477      Asia              Master's                  Y   \n",
       "25478      Asia              Master's                  Y   \n",
       "25479      Asia            Bachelor's                  Y   \n",
       "\n",
       "      requires_job_training  no_of_employees  yr_of_estab  \\\n",
       "0                         N            14513         2007   \n",
       "1                         N             2412         2002   \n",
       "2                         Y            44444         2008   \n",
       "3                         N               98         1897   \n",
       "4                         N             1082         2005   \n",
       "...                     ...              ...          ...   \n",
       "25475                     Y             2601         2008   \n",
       "25476                     N             3274         2006   \n",
       "25477                     N             1121         1910   \n",
       "25478                     Y             1918         1887   \n",
       "25479                     N             3195         1960   \n",
       "\n",
       "      region_of_employment  prevailing_wage unit_of_wage full_time_position  \\\n",
       "0                     West         592.2029         Hour                  Y   \n",
       "1                Northeast       83425.6500         Year                  Y   \n",
       "2                     West      122996.8600         Year                  Y   \n",
       "3                     West       83434.0300         Year                  Y   \n",
       "4                    South      149907.3900         Year                  Y   \n",
       "...                    ...              ...          ...                ...   \n",
       "25475                South       77092.5700         Year                  Y   \n",
       "25476            Northeast      279174.7900         Year                  Y   \n",
       "25477                South      146298.8500         Year                  N   \n",
       "25478                 West       86154.7700         Year                  Y   \n",
       "25479              Midwest       70876.9100         Year                  Y   \n",
       "\n",
       "       company_age  \n",
       "0               18  \n",
       "1               23  \n",
       "2               17  \n",
       "3              128  \n",
       "4               20  \n",
       "...            ...  \n",
       "25475           17  \n",
       "25476           19  \n",
       "25477          115  \n",
       "25478          138  \n",
       "25479           65  \n",
       "\n",
       "[25480 rows x 11 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dd95e72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=preprocessor.fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f363a663",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.combine import SMOTETomek, SMOTEENN\n",
    "\n",
    "# Resampling the minority class. The strategy can be changed as required.\n",
    "smt = SMOTEENN(random_state=42,sampling_strategy='minority' )\n",
    "# Fit the model to generate the data.\n",
    "x_res, y_res = smt.fit_resample(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "240b968f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((13629, 24), (3408, 24))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import  train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_res,y_res,test_size=0.2,random_state=42)\n",
    "x_train.shape, x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "378052e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report,ConfusionMatrixDisplay, \\\n",
    "                            precision_score, recall_score, f1_score, roc_auc_score,roc_curve \n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "49724e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(),\n",
    "    \"Logistic Regression\": LogisticRegression(),\n",
    "     \"K-Neighbors Classifier\": KNeighborsClassifier(),\n",
    "    \"XGBClassifier\": XGBClassifier(), \n",
    "     \"CatBoosting Classifier\": CatBoostClassifier(verbose=False),\n",
    "     \"Support Vector Classifier\": SVC(),\n",
    "    \"AdaBoost Classifier\": AdaBoostClassifier()\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "84246305",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def evaluate_clf(true, predicted):\n",
    "#     acc = accuracy_score(true, predicted) # Calculate Accuracy\n",
    "#     f1 = f1_score(true, predicted) # Calculate F1-score\n",
    "#     precision = precision_score(true, predicted) # Calculate Precision\n",
    "#     recall = recall_score(true, predicted)  # Calculate Recall\n",
    "#     roc_auc = roc_auc_score(true, predicted) #Calculate Roc\n",
    "#     return acc, f1 , precision, recall, roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "73d22d63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Evaluating model: Logistic Regression ---\n",
      "Model performance for Training set:\n",
      "- Accuracy: 1.0000\n",
      "- F1 score: 1.0000\n",
      "- Precision: 1.0000\n",
      "- Recall: 1.0000\n",
      "- Roc Auc Score: 0.0000\n",
      "----------------------------------\n",
      "Model performance for Test set:\n",
      "- Accuracy: 1.0000\n",
      "- F1 score: 1.0000\n",
      "- Precision: 1.0000\n",
      "- Recall: 1.0000\n",
      "- Roc Auc Score: 0.0000\n",
      "===================================\n",
      "\n",
      "\n",
      "--- Evaluating model: Decision Tree ---\n",
      "Model performance for Training set:\n",
      "- Accuracy: 1.0000\n",
      "- F1 score: 1.0000\n",
      "- Precision: 1.0000\n",
      "- Recall: 1.0000\n",
      "- Roc Auc Score: 0.0000\n",
      "----------------------------------\n",
      "Model performance for Test set:\n",
      "- Accuracy: 1.0000\n",
      "- F1 score: 1.0000\n",
      "- Precision: 1.0000\n",
      "- Recall: 1.0000\n",
      "- Roc Auc Score: 0.0000\n",
      "===================================\n",
      "\n",
      "\n",
      "\n",
      "=== Model Evaluation Report ===\n",
      "            Model Name  Accuracy  F1 Score  Precision  Recall  ROC AUC\n",
      "0  Logistic Regression       1.0       1.0        1.0     1.0      0.0\n",
      "1        Decision Tree       1.0       1.0        1.0     1.0      0.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.exceptions import NotFittedError\n",
    "\n",
    "# Define the positive class label string.\n",
    "# This should match one of the actual string labels in your 'y' data.\n",
    "POSITIVE_CLASS_LABEL = 'Certified'\n",
    "\n",
    "def evaluate_clf(y_true, y_pred, y_pred_proba=None, pos_label_encoded=1):\n",
    "    '''\n",
    "    Evaluates classification metrics.\n",
    "\n",
    "    Args:\n",
    "        y_true (array-like): True labels (expected to be numerical, e.g., 0 or 1).\n",
    "        y_pred (array-like): Predicted hard labels (expected to be numerical, e.g., 0 or 1).\n",
    "        y_pred_proba (array-like, optional): Predicted probabilities for the positive class.\n",
    "                                             Used for ROC AUC calculation. Defaults to None.\n",
    "        pos_label_encoded (int): The numerical label representing the positive class\n",
    "                                 (e.g., 1, after LabelEncoding). Defaults to 1.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing accuracy, F1 score, precision, recall, and ROC AUC score.\n",
    "    '''\n",
    "    # Accuracy score does not take 'pos_label'\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "\n",
    "    # For F1, Precision, Recall, use the numerical pos_label_encoded\n",
    "    f1 = f1_score(y_true, y_pred, pos_label=pos_label_encoded, average='binary')\n",
    "    precision = precision_score(y_true, y_pred, pos_label=pos_label_encoded, average='binary')\n",
    "    recall = recall_score(y_true, y_pred, pos_label=pos_label_encoded, average='binary')\n",
    "\n",
    "    rocauc_score_val = 0.0 # Initialize ROC AUC score\n",
    "\n",
    "    if y_pred_proba is not None:\n",
    "        # If probabilities are provided, use them for ROC AUC.\n",
    "        # y_true is already expected to be numerical (0/1) here.\n",
    "        rocauc_score_val = roc_auc_score(y_true, y_pred_proba)\n",
    "    else:\n",
    "        # If probabilities are not available, use hard predictions.\n",
    "        # Since y_true and y_pred are already 0/1 numerical, roc_auc_score can handle it.\n",
    "        rocauc_score_val = roc_auc_score(y_true, y_pred)\n",
    "\n",
    "    return accuracy, f1, precision, recall, rocauc_score_val\n",
    "\n",
    "def evaluate_models(x, y, models):\n",
    "    '''\n",
    "    This function takes in X (features), y (target), and a dictionary of models as input.\n",
    "    It performs train-test split, iterates through the given model dictionary,\n",
    "    and evaluates various classification metrics for each model.\n",
    "\n",
    "    Args:\n",
    "        x (DataFrame or array-like): Features dataset.\n",
    "        y (Series or array-like): Target variable (can be string labels).\n",
    "        models (dict): A dictionary where keys are model names (strings) and values\n",
    "                       are instantiated scikit-learn classifier models.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame containing a report of all models' metrics,\n",
    "                      sorted by accuracy in descending order.\n",
    "    '''\n",
    "    # Initialize LabelEncoder to convert string labels to numerical (0 and 1)\n",
    "    le = LabelEncoder()\n",
    "\n",
    "    # Fit and transform y BEFORE splitting the data.\n",
    "    # This ensures that both train and test sets have numerical labels (0 and 1).\n",
    "    y_encoded = le.fit_transform(y)\n",
    "\n",
    "    # Determine which numerical label corresponds to the defined POSITIVE_CLASS_LABEL.\n",
    "    # LabelEncoder assigns integers based on alphabetical order by default.\n",
    "    pos_label_mapping = {label: idx for idx, label in enumerate(le.classes_)}\n",
    "\n",
    "    if POSITIVE_CLASS_LABEL not in pos_label_mapping:\n",
    "        raise ValueError(\n",
    "            f\"The specified POSITIVE_CLASS_LABEL '{POSITIVE_CLASS_LABEL}' \"\n",
    "            f\"was not found in the unique values of 'y': {le.classes_}\"\n",
    "        )\n",
    "\n",
    "    # Store the numerical representation of your positive class\n",
    "    NUMERIC_POSITIVE_LABEL = pos_label_mapping[POSITIVE_CLASS_LABEL]\n",
    "    # The other label (for binary classification)\n",
    "    # NUMERIC_NEGATIVE_LABEL = 1 - NUMERIC_POSITIVE_LABEL # Not strictly needed for metrics but good for understanding\n",
    "\n",
    "    # Separate dataset into train and test sets using the encoded target variable\n",
    "    X_train, X_test, y_train_encoded, y_test_encoded = train_test_split(\n",
    "        x, y_encoded, test_size=0.2, random_state=42\n",
    "    )\n",
    "\n",
    "    # Lists to store model evaluation results\n",
    "    models_list = []\n",
    "    accuracy_list = []\n",
    "    auc_list = [] # Renamed from 'auc' to avoid conflict if 'auc' was used elsewhere\n",
    "    f1_scores = []\n",
    "    precision_scores = []\n",
    "    recall_scores = []\n",
    "\n",
    "    # Iterate through each model in the provided dictionary\n",
    "    for model_name, model in models.items(): # Use .items() for cleaner iteration\n",
    "        print(f\"--- Evaluating model: {model_name} ---\")\n",
    "\n",
    "        try:\n",
    "            # Train the model using the encoded training data\n",
    "            model.fit(X_train, y_train_encoded)\n",
    "\n",
    "            # Make predictions (these will also be numerical: 0 or 1)\n",
    "            y_train_pred = model.predict(X_train)\n",
    "            y_test_pred = model.predict(X_test)\n",
    "\n",
    "            # Get probabilities for ROC AUC if the model supports it\n",
    "            y_train_pred_proba = None\n",
    "            y_test_pred_proba = None\n",
    "            if hasattr(model, 'predict_proba'):\n",
    "                try:\n",
    "                    # Find the index of the positive class within the model's output classes.\n",
    "                    # This is crucial as model.classes_ order might vary.\n",
    "                    positive_class_proba_idx = list(model.classes_).index(NUMERIC_POSITIVE_LABEL)\n",
    "                    y_train_pred_proba = model.predict_proba(X_train)[:, positive_class_proba_idx]\n",
    "                    y_test_pred_proba = model.predict_proba(X_test)[:, positive_class_proba_idx]\n",
    "                except ValueError:\n",
    "                    print(f\"Warning: Numeric positive label '{NUMERIC_POSITIVE_LABEL}' \"\n",
    "                          f\"not found in model.classes_ for {model_name}. \"\n",
    "                          f\"ROC AUC will be calculated with hard predictions.\")\n",
    "                except NotFittedError:\n",
    "                    print(f\"Warning: Model {model_name} not fitted correctly for predict_proba. \"\n",
    "                          f\"ROC AUC will be calculated with hard predictions.\")\n",
    "                    pass # Fallback to calculating ROC AUC with hard predictions\n",
    "\n",
    "            # Evaluate training set performance\n",
    "            model_train_accuracy, model_train_f1, model_train_precision,\\\n",
    "            model_train_recall, model_train_rocauc_score = evaluate_clf(\n",
    "                y_train_encoded, y_train_pred, y_train_pred_proba, pos_label_encoded=NUMERIC_POSITIVE_LABEL\n",
    "            )\n",
    "\n",
    "            # Evaluate test set performance\n",
    "            model_test_accuracy, model_test_f1, model_test_precision,\\\n",
    "            model_test_recall, model_test_rocauc_score = evaluate_clf(\n",
    "                y_test_encoded, y_test_pred, y_test_pred_proba, pos_label_encoded=NUMERIC_POSITIVE_LABEL\n",
    "            )\n",
    "\n",
    "            # Append results to lists ONLY if all calculations were successful for this model\n",
    "            models_list.append(model_name)\n",
    "            accuracy_list.append(model_test_accuracy)\n",
    "            f1_scores.append(model_test_f1)\n",
    "            precision_scores.append(model_test_precision)\n",
    "            recall_scores.append(model_test_recall)\n",
    "            auc_list.append(model_test_rocauc_score)\n",
    "\n",
    "            # Print performance metrics for the training set\n",
    "            print('Model performance for Training set:')\n",
    "            print(f\"- Accuracy: {model_train_accuracy:.4f}\")\n",
    "            print(f\"- F1 score: {model_train_f1:.4f}\")\n",
    "            print(f\"- Precision: {model_train_precision:.4f}\")\n",
    "            print(f\"- Recall: {model_train_recall:.4f}\")\n",
    "            print(f\"- Roc Auc Score: {model_train_rocauc_score:.4f}\")\n",
    "\n",
    "            print('----------------------------------')\n",
    "\n",
    "            # Print performance metrics for the test set\n",
    "            print('Model performance for Test set:')\n",
    "            print(f\"- Accuracy: {model_test_accuracy:.4f}\")\n",
    "            print(f\"- F1 score: {model_test_f1:.4f}\")\n",
    "            print(f\"- Precision: {model_test_precision:.4f}\")\n",
    "            print(f\"- Recall: {model_test_recall:.4f}\")\n",
    "            print(f\"- Roc Auc Score: {model_test_rocauc_score:.4f}\")\n",
    "            print('='*35)\n",
    "            print('\\n')\n",
    "\n",
    "        except Exception as e:\n",
    "            # If any error occurs for a model, print an error message and skip to the next model\n",
    "            print(f\"Error evaluating model {model_name}: {e}\")\n",
    "            print(\"Skipping this model and continuing with the next.\")\n",
    "            print('='*35)\n",
    "            print('\\n')\n",
    "            # Do NOT append anything for this failed model to maintain list consistency\n",
    "            continue # Move to the next model in the loop\n",
    "\n",
    "    # Create the final report DataFrame from the collected lists\n",
    "    report_data = {\n",
    "        'Model Name': models_list,\n",
    "        'Accuracy': accuracy_list,\n",
    "        'F1 Score': f1_scores,\n",
    "        'Precision': precision_scores,\n",
    "        'Recall': recall_scores,\n",
    "        'ROC AUC': auc_list\n",
    "    }\n",
    "    report = pd.DataFrame(report_data).sort_values(by=['Accuracy'], ascending=False)\n",
    "\n",
    "    return report\n",
    "\n",
    "# --- Example Usage ---\n",
    "if __name__ == \"__main__\":\n",
    "    # Create some dummy data for demonstration\n",
    "    # X (features) - numerical data\n",
    "    data = {\n",
    "        'feature1': [10, 20, 15, 25, 30, 12, 18, 22, 28, 35, 11, 16, 21, 26, 31, 13, 19, 23, 29, 34],\n",
    "        'feature2': [1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0],\n",
    "        'feature3': [5, 8, 6, 9, 7, 5, 8, 6, 9, 7, 5, 8, 6, 9, 7, 5, 8, 6, 9, 7]\n",
    "    }\n",
    "    X = pd.DataFrame(data)\n",
    "\n",
    "    # y (target) - string labels ('Certified' or 'Denied')\n",
    "    y_labels = ['Certified', 'Denied', 'Certified', 'Denied', 'Certified',\n",
    "                'Denied', 'Certified', 'Denied', 'Certified', 'Denied',\n",
    "                'Certified', 'Denied', 'Certified', 'Denied', 'Certified',\n",
    "                'Denied', 'Certified', 'Denied', 'Certified', 'Denied']\n",
    "    y = pd.Series(y_labels)\n",
    "\n",
    "    # Define a dictionary of models to evaluate\n",
    "    # Ensure your models are instantiated correctly\n",
    "    models = {\n",
    "        'Logistic Regression': LogisticRegression(random_state=42, solver='liblinear'),\n",
    "        'Decision Tree': DecisionTreeClassifier(random_state=42),\n",
    "        # Add more models here, e.g., 'RandomForestClassifier': RandomForestClassifier(random_state=42)\n",
    "    }\n",
    "\n",
    "    # Evaluate the models\n",
    "    evaluation_report = evaluate_models(X, y, models)\n",
    "\n",
    "    # Print the final report\n",
    "    print(\"\\n=== Model Evaluation Report ===\")\n",
    "    print(evaluation_report)\n",
    "\n",
    "    # Example of a model that might cause an error for demonstration (e.g., a custom broken model)\n",
    "    # class BrokenModel:\n",
    "    #     def fit(self, X, y):\n",
    "    #         raise Exception(\"This model intentionally fails during fitting!\")\n",
    "    #     def predict(self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "13a21de7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Evaluating model: Logistic Regression ---\n",
      "Model performance for Training set:\n",
      "- Accuracy: 0.7385\n",
      "- F1 score: 0.7226\n",
      "- Precision: 0.7071\n",
      "- Recall: 0.7387\n",
      "- Roc Auc Score: 0.1722\n",
      "----------------------------------\n",
      "Model performance for Test set:\n",
      "- Accuracy: 0.7256\n",
      "- F1 score: 0.7081\n",
      "- Precision: 0.6936\n",
      "- Recall: 0.7232\n",
      "- Roc Auc Score: 0.1834\n",
      "===================================\n",
      "\n",
      "\n",
      "--- Evaluating model: Decision Tree ---\n",
      "Model performance for Training set:\n",
      "- Accuracy: 1.0000\n",
      "- F1 score: 1.0000\n",
      "- Precision: 1.0000\n",
      "- Recall: 1.0000\n",
      "- Roc Auc Score: 0.0000\n",
      "----------------------------------\n",
      "Model performance for Test set:\n",
      "- Accuracy: 0.9263\n",
      "- F1 score: 0.9193\n",
      "- Precision: 0.9273\n",
      "- Recall: 0.9114\n",
      "- Roc Auc Score: 0.0748\n",
      "===================================\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "base_model_report =evaluate_models(x=x_res, y=y_res, models=models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd09de3c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
